{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML HW Problem #1",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larrymoralez/ML-HW-1/blob/master/ML_HW_Problem_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1YBbjh_LSl51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#Load the MNIST Data set, split it into training and test sets, and convert it to 2D\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "\n",
        "#Can manipulate this digit variable to test the model for each or the 10 digits\n",
        "digit = 9\n",
        "\n",
        "for i in range(len(test_labels)):\n",
        "    if test_labels[i] == digit:\n",
        "        test_labels[i] = 1\n",
        "    else:\n",
        "        test_labels[i] = 0\n",
        "        \n",
        "for i in range(len(train_labels)):\n",
        "    if train_labels[i] == digit:\n",
        "        train_labels[i] = 1\n",
        "    else:\n",
        "        train_labels[i] = 0\n",
        "\n",
        "\n",
        "\n",
        "#mini batch or SGD? Then select random samples from train images. Experiment with whatever size batches.\n",
        "s = np.random.permutation(len(train_labels))\n",
        "\n",
        "  \n",
        "#Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "#Set initial model params and calculate gradient using LA\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "lr = 0.01\n",
        "np.random.seed(42)\n",
        "initial_weight = np.random.randn(784) #for problem 3, do the same thing for 10, 28, 28 matrix (10,784) or (784, 10)\n",
        "weight = initial_weight\n",
        "n = len(train_images)\n",
        "b = np.random.random_sample()\n",
        "\n",
        "#gradient for the weights, use one sample for every epoch in SGD. For problem 2 we have to\n",
        "#use a new formula to calculate the loss and take the derivatives of something else.\n",
        "\n",
        "\n",
        "#Binary Cross-entropy. -yloga - (1-y)log(1-a). Take derivative you get -y 1/a + (1-y) 1/1-a * a(1-a)\n",
        "# for epoch in range(epochs):\n",
        "#     for i in range(len(train_images)):\n",
        "#         xi = train_images[i]\n",
        "#         yi = train_labels[i]\n",
        "#         z = xi.T.dot(weight) + bias\n",
        "#         a = sigmoid(z)\n",
        "#         w_gradient = 2/n * xi.T.dot(a - yi)\n",
        "#         weight = weight - lr * w_gradient\n",
        "#         b_gradient = 2/n * (a - yi)\n",
        "#         b = b - lr * b_gradient\n",
        "        \n",
        "# print (weight, b)\n",
        "\n",
        "\n",
        "# #MSE Loss Function\n",
        "for epoch in range(epochs):\n",
        "    for i in range(batch_size):\n",
        "        offset = epoch * batch_size + i\n",
        "        xi = train_images[s[offset]]\n",
        "        yi = train_labels[s[offset]]\n",
        "        z = xi.T.dot(weight) + b\n",
        "        a = sigmoid(z)\n",
        "        w_gradient = (a-yi)*(a*(1-a))*xi          #aprime is a*(1-a), so (a-y)aprime\n",
        "        weight = weight - lr * w_gradient\n",
        "        b_gradient = (a-yi)*(a*(1-a))\n",
        "        b = b - lr * b_gradient\n",
        "\n",
        "        \n",
        "#Run test images through the model to get predictions\n",
        "        \n",
        "prediction_array = [0 for x in range(len(test_images))]\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "    x = test_images[i]\n",
        "    z = x.T.dot(weight) + b\n",
        "    a_predict = sigmoid(z)\n",
        "    if a_predict > 0.5:\n",
        "         a_predict = 1\n",
        "    else:\n",
        "         a_predict = 0\n",
        "    prediction_array[i] = a_predict\n",
        "\n",
        "\n",
        "#Check predictions and calculate accuracy    \n",
        "\n",
        "count_correct = 0\n",
        "\n",
        "for i in range(len(test_labels)):\n",
        "    y = test_labels[i]\n",
        "    if prediction_array[i] == 1 and test_labels[i] == 1:\n",
        "        count_correct = count_correct + 1\n",
        "    if prediction_array[i] == 0 and test_labels[i] == 0:\n",
        "        count_correct = count_correct + 1\n",
        "    accuracy = count_correct/(len(test_images))\n",
        "\n",
        "print(count_correct) \n",
        "print(accuracy) #For MSE the accuracy was %90.19"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}