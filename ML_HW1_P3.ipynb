{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML HW1 P3",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larrymoralez/ML-HW-1/blob/master/ML_HW1_P3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vejT2jnXXuph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#Load the MNIST Data set, split it into training and test sets, and convert it to 2D\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "# if run into problems use (60000, 784, 1)?\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "s = np.random.permutation(len(train_labels))\n",
        "\n",
        "\n",
        "#Define softmax function\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum() \n",
        "\n",
        "\n",
        "#Set initial parameters \n",
        "epochs = 10\n",
        "lr = 0.01\n",
        "np.random.seed(42)\n",
        "initial_weight = np.random.randn(784, 10) # needs to be same dimensions as train_images. #for problem 3, do the same thing for 10, 28, 28 matrix (10,784) or (784, 10)\n",
        "weight = initial_weight\n",
        "n = len(train_images)\n",
        "b = np.random.random_sample()\n",
        "delta = np.identity(10)\n",
        "\n",
        "#MSE loss function\n",
        "for epoch in range(epochs):\n",
        "    for i in range(len(train_images)):\n",
        "        xi = train_images[i]\n",
        "        yi = train_labels[i]\n",
        "        z = xi.T.dot(weight) + b\n",
        "        a = softmax(z)\n",
        "        w_gradient = yi * (delta - a) * xi          #aprime is a*(1-a), so (a-y)aprime, if the index of the test image argmax = test label\n",
        "#         weight = weight - lr * w_gradient\n",
        "#         b_gradient = (a-yi)*(a*(1-a))\n",
        "#         b = b - lr * b_gradient\n",
        "\n",
        "\n",
        "#Run test images through the model to get predictions       \n",
        "prediction_array = [0 for x in range(len(test_images))]\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "    x = test_images[i]\n",
        "    z = x.T.dot(weight) + b\n",
        "    a_predict = softmax(z)\n",
        "    prediction_array[i] = a_predict\n",
        "\n",
        "\n",
        "#Check predictions and calculate accuracy\n",
        "count_correct = 0\n",
        "\n",
        "for i in range(len(test_labels)):\n",
        "    y = test_labels[i]\n",
        "    if argmax.prediction_array[i] == argmax.y:\n",
        "        count_correct = count_correct + 1\n",
        "    accuracy = count_correct/(len(test_images))\n",
        "\n",
        "print(count_correct) \n",
        "print(accuracy) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}